{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%204%20-%20Lesson%202%20-%20Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Download punkt_tab resource\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Read the Wikipedia text file\n",
        "with open('wikipedia.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Split into sentences first\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "cleaned_sentences = []\n",
        "\n",
        "for sentence in sentences:\n",
        "    # Lowercase\n",
        "    sentence = sentence.lower()\n",
        "    # Remove all characters except letters and spaces\n",
        "    sentence = re.sub(r'[^a-z\\s]', '', sentence)\n",
        "    # Remove extra spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
        "    # Remove stopwords\n",
        "    words = sentence.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    cleaned_sentence = ' '.join(words)\n",
        "\n",
        "    # Add sentence only if not empty\n",
        "    if cleaned_sentence:\n",
        "        cleaned_sentences.append(cleaned_sentence)\n",
        "\n",
        "corpus = list(set(cleaned_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugyLt14lZgbx",
        "outputId": "4ff0ee1e-3f4e-4edb-d9b7-f634f6e38f7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxhzNewhZgmJ",
        "outputId": "32fc0e80-65d0-48e2-abf0-2462cbf4c8de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['work perceive environment agent receives information various inputs text voice sensor data',\n",
              " 'learning adaptability agents improve performance time learning experiences consequences actions',\n",
              " 'video explains fundamentals ai agents including components capabilitieskey characteristics ai agent perception agents gather information environment sensors input data',\n",
              " 'understand reason using llms ai techniques agent processes information understand users intent current state environment',\n",
              " 'adapt learn agent may receive feedback actions uses refine strategies improve future performance',\n",
              " 'agents use ai particularly large language models llms understand respond user requests gather information plan workflows interact tools solve complex problems',\n",
              " 'demonstrate autonomy learning adaptability allowing improve performance time even work agents multiagent systems coordinate perform complex operations',\n",
              " 'autonomy operate independently making decisions carrying tasks without constant human intervention',\n",
              " 'goaloriented agents programmed specific objectives strive achieve performing necessary tasks',\n",
              " 'action agents perform actions environment whether thats physical environment like robot vacuum digital one like customer support system',\n",
              " 'plan execute actions based goals understanding agent formulates plan uses available tools execute necessary steps',\n",
              " 'ai agent software system designed act autonomously achieve specific goals perceiving environment making decisions taking actions complete tasks',\n",
              " 'decisionmaking reasoning use logic planning memory decide best course action achieve goal']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRnDnCW-Z7qv"
      },
      "source": [
        "tokenizer = Tokenizer()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a6jTgWhzPXo",
        "outputId": "b7ecfc5f-ab49-4eb1-938e-a5d444419e1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agents': 1, 'environment': 2, 'agent': 3, 'actions': 4, 'ai': 5, 'information': 6, 'learning': 7, 'improve': 8, 'performance': 9, 'understand': 10, 'plan': 11, 'tasks': 12, 'achieve': 13, 'work': 14, 'data': 15, 'adaptability': 16, 'time': 17, 'gather': 18, 'llms': 19, 'uses': 20, 'use': 21, 'tools': 22, 'complex': 23, 'autonomy': 24, 'perform': 25, 'making': 26, 'decisions': 27, 'specific': 28, 'necessary': 29, 'action': 30, 'like': 31, 'system': 32, 'execute': 33, 'goals': 34, 'perceive': 35, 'receives': 36, 'various': 37, 'inputs': 38, 'text': 39, 'voice': 40, 'sensor': 41, 'experiences': 42, 'consequences': 43, 'video': 44, 'explains': 45, 'fundamentals': 46, 'including': 47, 'components': 48, 'capabilitieskey': 49, 'characteristics': 50, 'perception': 51, 'sensors': 52, 'input': 53, 'reason': 54, 'using': 55, 'techniques': 56, 'processes': 57, 'users': 58, 'intent': 59, 'current': 60, 'state': 61, 'adapt': 62, 'learn': 63, 'may': 64, 'receive': 65, 'feedback': 66, 'refine': 67, 'strategies': 68, 'future': 69, 'particularly': 70, 'large': 71, 'language': 72, 'models': 73, 'respond': 74, 'user': 75, 'requests': 76, 'workflows': 77, 'interact': 78, 'solve': 79, 'problems': 80, 'demonstrate': 81, 'allowing': 82, 'even': 83, 'multiagent': 84, 'systems': 85, 'coordinate': 86, 'operations': 87, 'operate': 88, 'independently': 89, 'carrying': 90, 'without': 91, 'constant': 92, 'human': 93, 'intervention': 94, 'goaloriented': 95, 'programmed': 96, 'objectives': 97, 'strive': 98, 'performing': 99, 'whether': 100, 'thats': 101, 'physical': 102, 'robot': 103, 'vacuum': 104, 'digital': 105, 'one': 106, 'customer': 107, 'support': 108, 'based': 109, 'understanding': 110, 'formulates': 111, 'available': 112, 'steps': 113, 'software': 114, 'designed': 115, 'act': 116, 'autonomously': 117, 'perceiving': 118, 'taking': 119, 'complete': 120, 'decisionmaking': 121, 'reasoning': 122, 'logic': 123, 'planning': 124, 'memory': 125, 'decide': 126, 'best': 127, 'course': 128, 'goal': 129}\n",
            "130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "\n",
        "for line in corpus:\n",
        "  print([line])\n",
        "  #break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EdnGRmjzuBZ",
        "outputId": "947668b5-1b2a-41ad-e51f-1ba5716153fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['work perceive environment agent receives information various inputs text voice sensor data']\n",
            "['learning adaptability agents improve performance time learning experiences consequences actions']\n",
            "['video explains fundamentals ai agents including components capabilitieskey characteristics ai agent perception agents gather information environment sensors input data']\n",
            "['understand reason using llms ai techniques agent processes information understand users intent current state environment']\n",
            "['adapt learn agent may receive feedback actions uses refine strategies improve future performance']\n",
            "['agents use ai particularly large language models llms understand respond user requests gather information plan workflows interact tools solve complex problems']\n",
            "['demonstrate autonomy learning adaptability allowing improve performance time even work agents multiagent systems coordinate perform complex operations']\n",
            "['autonomy operate independently making decisions carrying tasks without constant human intervention']\n",
            "['goaloriented agents programmed specific objectives strive achieve performing necessary tasks']\n",
            "['action agents perform actions environment whether thats physical environment like robot vacuum digital one like customer support system']\n",
            "['plan execute actions based goals understanding agent formulates plan uses available tools execute necessary steps']\n",
            "['ai agent software system designed act autonomously achieve specific goals perceiving environment making decisions taking actions complete tasks']\n",
            "['decisionmaking reasoning use logic planning memory decide best course action achieve goal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    print(token_list)\n",
        "    #break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roX1C3WZjduk",
        "outputId": "a34801f6-7e07-4afa-901a-eb2ab5cfc16f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14, 35, 2, 3, 36, 6, 37, 38, 39, 40, 41, 15]\n",
            "[7, 16, 1, 8, 9, 17, 7, 42, 43, 4]\n",
            "[44, 45, 46, 5, 1, 47, 48, 49, 50, 5, 3, 51, 1, 18, 6, 2, 52, 53, 15]\n",
            "[10, 54, 55, 19, 5, 56, 3, 57, 6, 10, 58, 59, 60, 61, 2]\n",
            "[62, 63, 3, 64, 65, 66, 4, 20, 67, 68, 8, 69, 9]\n",
            "[1, 21, 5, 70, 71, 72, 73, 19, 10, 74, 75, 76, 18, 6, 11, 77, 78, 22, 79, 23, 80]\n",
            "[81, 24, 7, 16, 82, 8, 9, 17, 83, 14, 1, 84, 85, 86, 25, 23, 87]\n",
            "[24, 88, 89, 26, 27, 90, 12, 91, 92, 93, 94]\n",
            "[95, 1, 96, 28, 97, 98, 13, 99, 29, 12]\n",
            "[30, 1, 25, 4, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32]\n",
            "[11, 33, 4, 109, 34, 110, 3, 111, 11, 20, 112, 22, 33, 29, 113]\n",
            "[5, 3, 114, 32, 115, 116, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12]\n",
            "[121, 122, 21, 123, 124, 125, 126, 127, 128, 30, 13, 129]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "tP84Xni3zIAI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUjhuWnBjLPk",
        "outputId": "2e42c41a-49ea-45db-ab19-27922cae1873"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[14, 35],\n",
              " [14, 35, 2],\n",
              " [14, 35, 2, 3],\n",
              " [14, 35, 2, 3, 36],\n",
              " [14, 35, 2, 3, 36, 6],\n",
              " [14, 35, 2, 3, 36, 6, 37],\n",
              " [14, 35, 2, 3, 36, 6, 37, 38],\n",
              " [14, 35, 2, 3, 36, 6, 37, 38, 39],\n",
              " [14, 35, 2, 3, 36, 6, 37, 38, 39, 40],\n",
              " [14, 35, 2, 3, 36, 6, 37, 38, 39, 40, 41],\n",
              " [14, 35, 2, 3, 36, 6, 37, 38, 39, 40, 41, 15],\n",
              " [7, 16],\n",
              " [7, 16, 1],\n",
              " [7, 16, 1, 8],\n",
              " [7, 16, 1, 8, 9],\n",
              " [7, 16, 1, 8, 9, 17],\n",
              " [7, 16, 1, 8, 9, 17, 7],\n",
              " [7, 16, 1, 8, 9, 17, 7, 42],\n",
              " [7, 16, 1, 8, 9, 17, 7, 42, 43],\n",
              " [7, 16, 1, 8, 9, 17, 7, 42, 43, 4],\n",
              " [44, 45],\n",
              " [44, 45, 46],\n",
              " [44, 45, 46, 5],\n",
              " [44, 45, 46, 5, 1],\n",
              " [44, 45, 46, 5, 1, 47],\n",
              " [44, 45, 46, 5, 1, 47, 48],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49, 50],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49, 50, 5],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49, 50, 5, 3],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49, 50, 5, 3, 51],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49, 50, 5, 3, 51, 1],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49, 50, 5, 3, 51, 1, 18],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49, 50, 5, 3, 51, 1, 18, 6],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49, 50, 5, 3, 51, 1, 18, 6, 2],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49, 50, 5, 3, 51, 1, 18, 6, 2, 52],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49, 50, 5, 3, 51, 1, 18, 6, 2, 52, 53],\n",
              " [44, 45, 46, 5, 1, 47, 48, 49, 50, 5, 3, 51, 1, 18, 6, 2, 52, 53, 15],\n",
              " [10, 54],\n",
              " [10, 54, 55],\n",
              " [10, 54, 55, 19],\n",
              " [10, 54, 55, 19, 5],\n",
              " [10, 54, 55, 19, 5, 56],\n",
              " [10, 54, 55, 19, 5, 56, 3],\n",
              " [10, 54, 55, 19, 5, 56, 3, 57],\n",
              " [10, 54, 55, 19, 5, 56, 3, 57, 6],\n",
              " [10, 54, 55, 19, 5, 56, 3, 57, 6, 10],\n",
              " [10, 54, 55, 19, 5, 56, 3, 57, 6, 10, 58],\n",
              " [10, 54, 55, 19, 5, 56, 3, 57, 6, 10, 58, 59],\n",
              " [10, 54, 55, 19, 5, 56, 3, 57, 6, 10, 58, 59, 60],\n",
              " [10, 54, 55, 19, 5, 56, 3, 57, 6, 10, 58, 59, 60, 61],\n",
              " [10, 54, 55, 19, 5, 56, 3, 57, 6, 10, 58, 59, 60, 61, 2],\n",
              " [62, 63],\n",
              " [62, 63, 3],\n",
              " [62, 63, 3, 64],\n",
              " [62, 63, 3, 64, 65],\n",
              " [62, 63, 3, 64, 65, 66],\n",
              " [62, 63, 3, 64, 65, 66, 4],\n",
              " [62, 63, 3, 64, 65, 66, 4, 20],\n",
              " [62, 63, 3, 64, 65, 66, 4, 20, 67],\n",
              " [62, 63, 3, 64, 65, 66, 4, 20, 67, 68],\n",
              " [62, 63, 3, 64, 65, 66, 4, 20, 67, 68, 8],\n",
              " [62, 63, 3, 64, 65, 66, 4, 20, 67, 68, 8, 69],\n",
              " [62, 63, 3, 64, 65, 66, 4, 20, 67, 68, 8, 69, 9],\n",
              " [1, 21],\n",
              " [1, 21, 5],\n",
              " [1, 21, 5, 70],\n",
              " [1, 21, 5, 70, 71],\n",
              " [1, 21, 5, 70, 71, 72],\n",
              " [1, 21, 5, 70, 71, 72, 73],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10, 74],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10, 74, 75],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10, 74, 75, 76],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10, 74, 75, 76, 18],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10, 74, 75, 76, 18, 6],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10, 74, 75, 76, 18, 6, 11],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10, 74, 75, 76, 18, 6, 11, 77],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10, 74, 75, 76, 18, 6, 11, 77, 78],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10, 74, 75, 76, 18, 6, 11, 77, 78, 22],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10, 74, 75, 76, 18, 6, 11, 77, 78, 22, 79],\n",
              " [1, 21, 5, 70, 71, 72, 73, 19, 10, 74, 75, 76, 18, 6, 11, 77, 78, 22, 79, 23],\n",
              " [1,\n",
              "  21,\n",
              "  5,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  73,\n",
              "  19,\n",
              "  10,\n",
              "  74,\n",
              "  75,\n",
              "  76,\n",
              "  18,\n",
              "  6,\n",
              "  11,\n",
              "  77,\n",
              "  78,\n",
              "  22,\n",
              "  79,\n",
              "  23,\n",
              "  80],\n",
              " [81, 24],\n",
              " [81, 24, 7],\n",
              " [81, 24, 7, 16],\n",
              " [81, 24, 7, 16, 82],\n",
              " [81, 24, 7, 16, 82, 8],\n",
              " [81, 24, 7, 16, 82, 8, 9],\n",
              " [81, 24, 7, 16, 82, 8, 9, 17],\n",
              " [81, 24, 7, 16, 82, 8, 9, 17, 83],\n",
              " [81, 24, 7, 16, 82, 8, 9, 17, 83, 14],\n",
              " [81, 24, 7, 16, 82, 8, 9, 17, 83, 14, 1],\n",
              " [81, 24, 7, 16, 82, 8, 9, 17, 83, 14, 1, 84],\n",
              " [81, 24, 7, 16, 82, 8, 9, 17, 83, 14, 1, 84, 85],\n",
              " [81, 24, 7, 16, 82, 8, 9, 17, 83, 14, 1, 84, 85, 86],\n",
              " [81, 24, 7, 16, 82, 8, 9, 17, 83, 14, 1, 84, 85, 86, 25],\n",
              " [81, 24, 7, 16, 82, 8, 9, 17, 83, 14, 1, 84, 85, 86, 25, 23],\n",
              " [81, 24, 7, 16, 82, 8, 9, 17, 83, 14, 1, 84, 85, 86, 25, 23, 87],\n",
              " [24, 88],\n",
              " [24, 88, 89],\n",
              " [24, 88, 89, 26],\n",
              " [24, 88, 89, 26, 27],\n",
              " [24, 88, 89, 26, 27, 90],\n",
              " [24, 88, 89, 26, 27, 90, 12],\n",
              " [24, 88, 89, 26, 27, 90, 12, 91],\n",
              " [24, 88, 89, 26, 27, 90, 12, 91, 92],\n",
              " [24, 88, 89, 26, 27, 90, 12, 91, 92, 93],\n",
              " [24, 88, 89, 26, 27, 90, 12, 91, 92, 93, 94],\n",
              " [95, 1],\n",
              " [95, 1, 96],\n",
              " [95, 1, 96, 28],\n",
              " [95, 1, 96, 28, 97],\n",
              " [95, 1, 96, 28, 97, 98],\n",
              " [95, 1, 96, 28, 97, 98, 13],\n",
              " [95, 1, 96, 28, 97, 98, 13, 99],\n",
              " [95, 1, 96, 28, 97, 98, 13, 99, 29],\n",
              " [95, 1, 96, 28, 97, 98, 13, 99, 29, 12],\n",
              " [30, 1],\n",
              " [30, 1, 25],\n",
              " [30, 1, 25, 4],\n",
              " [30, 1, 25, 4, 2],\n",
              " [30, 1, 25, 4, 2, 100],\n",
              " [30, 1, 25, 4, 2, 100, 101],\n",
              " [30, 1, 25, 4, 2, 100, 101, 102],\n",
              " [30, 1, 25, 4, 2, 100, 101, 102, 2],\n",
              " [30, 1, 25, 4, 2, 100, 101, 102, 2, 31],\n",
              " [30, 1, 25, 4, 2, 100, 101, 102, 2, 31, 103],\n",
              " [30, 1, 25, 4, 2, 100, 101, 102, 2, 31, 103, 104],\n",
              " [30, 1, 25, 4, 2, 100, 101, 102, 2, 31, 103, 104, 105],\n",
              " [30, 1, 25, 4, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106],\n",
              " [30, 1, 25, 4, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31],\n",
              " [30, 1, 25, 4, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107],\n",
              " [30, 1, 25, 4, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108],\n",
              " [30, 1, 25, 4, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32],\n",
              " [11, 33],\n",
              " [11, 33, 4],\n",
              " [11, 33, 4, 109],\n",
              " [11, 33, 4, 109, 34],\n",
              " [11, 33, 4, 109, 34, 110],\n",
              " [11, 33, 4, 109, 34, 110, 3],\n",
              " [11, 33, 4, 109, 34, 110, 3, 111],\n",
              " [11, 33, 4, 109, 34, 110, 3, 111, 11],\n",
              " [11, 33, 4, 109, 34, 110, 3, 111, 11, 20],\n",
              " [11, 33, 4, 109, 34, 110, 3, 111, 11, 20, 112],\n",
              " [11, 33, 4, 109, 34, 110, 3, 111, 11, 20, 112, 22],\n",
              " [11, 33, 4, 109, 34, 110, 3, 111, 11, 20, 112, 22, 33],\n",
              " [11, 33, 4, 109, 34, 110, 3, 111, 11, 20, 112, 22, 33, 29],\n",
              " [11, 33, 4, 109, 34, 110, 3, 111, 11, 20, 112, 22, 33, 29, 113],\n",
              " [5, 3],\n",
              " [5, 3, 114],\n",
              " [5, 3, 114, 32],\n",
              " [5, 3, 114, 32, 115],\n",
              " [5, 3, 114, 32, 115, 116],\n",
              " [5, 3, 114, 32, 115, 116, 117],\n",
              " [5, 3, 114, 32, 115, 116, 117, 13],\n",
              " [5, 3, 114, 32, 115, 116, 117, 13, 28],\n",
              " [5, 3, 114, 32, 115, 116, 117, 13, 28, 34],\n",
              " [5, 3, 114, 32, 115, 116, 117, 13, 28, 34, 118],\n",
              " [5, 3, 114, 32, 115, 116, 117, 13, 28, 34, 118, 2],\n",
              " [5, 3, 114, 32, 115, 116, 117, 13, 28, 34, 118, 2, 26],\n",
              " [5, 3, 114, 32, 115, 116, 117, 13, 28, 34, 118, 2, 26, 27],\n",
              " [5, 3, 114, 32, 115, 116, 117, 13, 28, 34, 118, 2, 26, 27, 119],\n",
              " [5, 3, 114, 32, 115, 116, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4],\n",
              " [5, 3, 114, 32, 115, 116, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120],\n",
              " [5, 3, 114, 32, 115, 116, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12],\n",
              " [121, 122],\n",
              " [121, 122, 21],\n",
              " [121, 122, 21, 123],\n",
              " [121, 122, 21, 123, 124],\n",
              " [121, 122, 21, 123, 124, 125],\n",
              " [121, 122, 21, 123, 124, 125, 126],\n",
              " [121, 122, 21, 123, 124, 125, 126, 127],\n",
              " [121, 122, 21, 123, 124, 125, 126, 127, 128],\n",
              " [121, 122, 21, 123, 124, 125, 126, 127, 128, 30],\n",
              " [121, 122, 21, 123, 124, 125, 126, 127, 128, 30, 13],\n",
              " [121, 122, 21, 123, 124, 125, 126, 127, 128, 30, 13, 129]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soPGVheskaQP"
      },
      "source": [
        "# pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIg0e4mAf1PG",
        "outputId": "14aec2b7-25bb-4c66-a94c-6d6d3b78204f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivVBkCMWkg7v",
        "outputId": "c632f639-626e-451b-f13c-a70c2abe9ed2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  14,  35],\n",
              "       [  0,   0,   0, ...,  14,  35,   2],\n",
              "       [  0,   0,   0, ...,  35,   2,   3],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 127, 128,  30],\n",
              "       [  0,   0,   0, ..., 128,  30,  13],\n",
              "       [  0,   0,   0, ...,  30,  13, 129]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "xs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxWx6rTjkjLB",
        "outputId": "07be1d5b-fb88-4a5c-f13c-61a983680825"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,  14],\n",
              "       [  0,   0,   0, ...,   0,  14,  35],\n",
              "       [  0,   0,   0, ...,  14,  35,   2],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 126, 127, 128],\n",
              "       [  0,   0,   0, ..., 127, 128,  30],\n",
              "       [  0,   0,   0, ..., 128,  30,  13]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ9g0jYpk9R2",
        "outputId": "31f156cc-3178-4b64-d5f6-0f040aa67330"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n",
        "ys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XU2kt6GkycY",
        "outputId": "d7973633-3c34-4f48-9ff5-c781a3703721"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 130)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4myRpB1c4Gg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c554e8-d66b-4f47-d556-6870ac2abb31"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agents': 1, 'environment': 2, 'agent': 3, 'actions': 4, 'ai': 5, 'information': 6, 'learning': 7, 'improve': 8, 'performance': 9, 'understand': 10, 'plan': 11, 'tasks': 12, 'achieve': 13, 'work': 14, 'data': 15, 'adaptability': 16, 'time': 17, 'gather': 18, 'llms': 19, 'uses': 20, 'use': 21, 'tools': 22, 'complex': 23, 'autonomy': 24, 'perform': 25, 'making': 26, 'decisions': 27, 'specific': 28, 'necessary': 29, 'action': 30, 'like': 31, 'system': 32, 'execute': 33, 'goals': 34, 'perceive': 35, 'receives': 36, 'various': 37, 'inputs': 38, 'text': 39, 'voice': 40, 'sensor': 41, 'experiences': 42, 'consequences': 43, 'video': 44, 'explains': 45, 'fundamentals': 46, 'including': 47, 'components': 48, 'capabilitieskey': 49, 'characteristics': 50, 'perception': 51, 'sensors': 52, 'input': 53, 'reason': 54, 'using': 55, 'techniques': 56, 'processes': 57, 'users': 58, 'intent': 59, 'current': 60, 'state': 61, 'adapt': 62, 'learn': 63, 'may': 64, 'receive': 65, 'feedback': 66, 'refine': 67, 'strategies': 68, 'future': 69, 'particularly': 70, 'large': 71, 'language': 72, 'models': 73, 'respond': 74, 'user': 75, 'requests': 76, 'workflows': 77, 'interact': 78, 'solve': 79, 'problems': 80, 'demonstrate': 81, 'allowing': 82, 'even': 83, 'multiagent': 84, 'systems': 85, 'coordinate': 86, 'operations': 87, 'operate': 88, 'independently': 89, 'carrying': 90, 'without': 91, 'constant': 92, 'human': 93, 'intervention': 94, 'goaloriented': 95, 'programmed': 96, 'objectives': 97, 'strive': 98, 'performing': 99, 'whether': 100, 'thats': 101, 'physical': 102, 'robot': 103, 'vacuum': 104, 'digital': 105, 'one': 106, 'customer': 107, 'support': 108, 'based': 109, 'understanding': 110, 'formulates': 111, 'available': 112, 'steps': 113, 'software': 114, 'designed': 115, 'act': 116, 'autonomously': 117, 'perceiving': 118, 'taking': 119, 'complete': 120, 'decisionmaking': 121, 'reasoning': 122, 'logic': 123, 'planning': 124, 'memory': 125, 'decide': 126, 'best': 127, 'course': 128, 'goal': 129}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_words, max_sequence_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp3JsT9DlbCa",
        "outputId": "df148a14-cf92-42a7-a13f-b6e4f4440e65"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf6aa73-363c-45c0-e398-4d9de17b52b0"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "adam = Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "history = model.fit(xs, ys, epochs=100, verbose=1)\n",
        "#print model.summary()\n",
        "print(model)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.0200 - loss: 4.8774   \n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0279 - loss: 4.8268    \n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0568 - loss: 4.5442\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0839 - loss: 4.1850\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1077 - loss: 3.7140\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1406 - loss: 3.2538\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2504 - loss: 2.6263\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3260 - loss: 2.1436\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4201 - loss: 1.7019\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5254 - loss: 1.4676\n",
            "Epoch 11/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6583 - loss: 1.1309\n",
            "Epoch 12/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7185 - loss: 0.8998\n",
            "Epoch 13/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8468 - loss: 0.6552\n",
            "Epoch 14/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8509 - loss: 0.5497\n",
            "Epoch 15/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9224 - loss: 0.3803\n",
            "Epoch 16/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9768 - loss: 0.2781\n",
            "Epoch 17/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9725 - loss: 0.2094\n",
            "Epoch 18/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9939 - loss: 0.1377\n",
            "Epoch 19/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0913\n",
            "Epoch 20/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0591\n",
            "Epoch 21/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0485\n",
            "Epoch 22/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9964 - loss: 0.0405\n",
            "Epoch 23/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0261\n",
            "Epoch 24/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0235\n",
            "Epoch 25/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0184\n",
            "Epoch 26/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0175\n",
            "Epoch 27/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0143\n",
            "Epoch 28/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0120\n",
            "Epoch 29/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0112\n",
            "Epoch 30/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0104\n",
            "Epoch 31/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0100\n",
            "Epoch 32/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0088\n",
            "Epoch 33/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0079\n",
            "Epoch 34/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0078\n",
            "Epoch 35/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0075\n",
            "Epoch 36/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0067\n",
            "Epoch 37/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0063\n",
            "Epoch 38/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0059\n",
            "Epoch 39/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0057\n",
            "Epoch 40/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0053\n",
            "Epoch 41/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0051\n",
            "Epoch 42/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0047\n",
            "Epoch 43/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0044\n",
            "Epoch 44/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0043\n",
            "Epoch 45/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0038\n",
            "Epoch 46/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0039\n",
            "Epoch 47/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0036\n",
            "Epoch 48/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0036\n",
            "Epoch 49/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0034\n",
            "Epoch 50/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0033\n",
            "Epoch 51/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0030\n",
            "Epoch 52/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0029\n",
            "Epoch 53/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0029\n",
            "Epoch 54/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 55/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 56/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0025\n",
            "Epoch 57/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0025\n",
            "Epoch 58/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 59/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 60/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0022\n",
            "Epoch 61/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0022\n",
            "Epoch 62/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 63/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 64/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 65/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 66/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 67/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 68/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 69/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 70/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 71/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 72/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 73/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 74/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 75/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 76/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 77/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 78/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 79/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 80/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0012\n",
            "Epoch 81/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 82/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 83/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0012\n",
            "Epoch 84/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0012\n",
            "Epoch 85/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 86/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 87/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0010\n",
            "Epoch 88/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 9.9006e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 9.6071e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 9.3515e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.5522e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.3249e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 8.9377e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 8.7066e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 8.5576e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 8.3287e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 8.5231e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 8.0117e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.8745e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 7.6925e-04\n",
            "<Sequential name=sequential, built=True>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YXGelKThoTT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poeprYK8h-c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "65e31efa-d88a-4f1d-de74-823c01cd6ac1"
      },
      "source": [
        "plot_graphs(history, 'accuracy')\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8187cbc0-630a-4788-af70-f79a7e85e190"
      },
      "source": [
        "seed_text = \"agentic ai in future\"\n",
        "next_words = 100\n",
        "\n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "agentic ai in future agent software system designed autonomously achieve specific goals perceiving environment making decisions taking actions complete tasks tasks without goal intervention intervention system perceiving environment system environment whether thats physical environment like robot vacuum digital one like customer support system system tools tools execute customer problems problems problems problems problems system tools taking complete learning adaptability agents improve performance time learning experiences consequences actions actions coordinate coordinate perform complex operations operations performing like customer one like customer support system system tools tools solve complex problems problems problems performing necessary tasks tasks without constant human intervention perform based goals understanding agent formulates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"agentic ai use cases are\"\n",
        "next_words = 100\n",
        "\n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    print(f\"token_list is: {token_list}\")\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    print(f\"token_list is after padding: {token_list}\")\n",
        "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "    print(f\"after argmax: {predicted}\")\n",
        "    output_word = \"\"\n",
        "    #print(f\"tokenizer word-index: {tokenizer.word_index.items()}\")\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsTpgIjWnxi8",
        "outputId": "6d5e6a62-9192-4e7f-fad2-6e72a3141126"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token_list is: [5, 21]\n",
            "token_list is after padding: [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5 21]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [3]\n",
            "token_list is: [5, 21, 3]\n",
            "token_list is after padding: [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5 21  3]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "after argmax: [114]\n",
            "token_list is: [5, 21, 3, 114]\n",
            "token_list is after padding: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5  21\n",
            "    3 114]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "after argmax: [32]\n",
            "token_list is: [5, 21, 3, 114, 32]\n",
            "token_list is after padding: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5  21   3\n",
            "  114  32]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "after argmax: [115]\n",
            "token_list is: [5, 21, 3, 114, 32, 115]\n",
            "token_list is after padding: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   5  21   3 114\n",
            "   32 115]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "after argmax: [117]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117]\n",
            "token_list is after padding: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   5  21   3 114  32\n",
            "  115 117]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "after argmax: [13]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13]\n",
            "token_list is after padding: [[  0   0   0   0   0   0   0   0   0   0   0   0   5  21   3 114  32 115\n",
            "  117  13]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "after argmax: [28]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28]\n",
            "token_list is after padding: [[  0   0   0   0   0   0   0   0   0   0   0   5  21   3 114  32 115 117\n",
            "   13  28]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [34]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34]\n",
            "token_list is after padding: [[  0   0   0   0   0   0   0   0   0   0   5  21   3 114  32 115 117  13\n",
            "   28  34]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [118]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118]\n",
            "token_list is after padding: [[  0   0   0   0   0   0   0   0   0   5  21   3 114  32 115 117  13  28\n",
            "   34 118]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "after argmax: [2]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2]\n",
            "token_list is after padding: [[  0   0   0   0   0   0   0   0   5  21   3 114  32 115 117  13  28  34\n",
            "  118   2]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [26]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26]\n",
            "token_list is after padding: [[  0   0   0   0   0   0   0   5  21   3 114  32 115 117  13  28  34 118\n",
            "    2  26]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "after argmax: [27]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27]\n",
            "token_list is after padding: [[  0   0   0   0   0   0   5  21   3 114  32 115 117  13  28  34 118   2\n",
            "   26  27]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [119]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119]\n",
            "token_list is after padding: [[  0   0   0   0   0   5  21   3 114  32 115 117  13  28  34 118   2  26\n",
            "   27 119]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "after argmax: [4]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4]\n",
            "token_list is after padding: [[  0   0   0   0   5  21   3 114  32 115 117  13  28  34 118   2  26  27\n",
            "  119   4]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [120]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120]\n",
            "token_list is after padding: [[  0   0   0   5  21   3 114  32 115 117  13  28  34 118   2  26  27 119\n",
            "    4 120]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [12]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12]\n",
            "token_list is after padding: [[  0   0   5  21   3 114  32 115 117  13  28  34 118   2  26  27 119   4\n",
            "  120  12]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [12]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12]\n",
            "token_list is after padding: [[  0   5  21   3 114  32 115 117  13  28  34 118   2  26  27 119   4 120\n",
            "   12  12]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "after argmax: [91]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91]\n",
            "token_list is after padding: [[  5  21   3 114  32 115 117  13  28  34 118   2  26  27 119   4 120  12\n",
            "   12  91]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "after argmax: [129]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129]\n",
            "token_list is after padding: [[ 21   3 114  32 115 117  13  28  34 118   2  26  27 119   4 120  12  12\n",
            "   91 129]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "after argmax: [94]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94]\n",
            "token_list is after padding: [[  3 114  32 115 117  13  28  34 118   2  26  27 119   4 120  12  12  91\n",
            "  129  94]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "after argmax: [94]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94]\n",
            "token_list is after padding: [[114  32 115 117  13  28  34 118   2  26  27 119   4 120  12  12  91 129\n",
            "   94  94]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "after argmax: [32]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32]\n",
            "token_list is after padding: [[ 32 115 117  13  28  34 118   2  26  27 119   4 120  12  12  91 129  94\n",
            "   94  32]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "after argmax: [118]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118]\n",
            "token_list is after padding: [[115 117  13  28  34 118   2  26  27 119   4 120  12  12  91 129  94  94\n",
            "   32 118]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "after argmax: [2]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2]\n",
            "token_list is after padding: [[117  13  28  34 118   2  26  27 119   4 120  12  12  91 129  94  94  32\n",
            "  118   2]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "after argmax: [32]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32]\n",
            "token_list is after padding: [[ 13  28  34 118   2  26  27 119   4 120  12  12  91 129  94  94  32 118\n",
            "    2  32]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [2]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2]\n",
            "token_list is after padding: [[ 28  34 118   2  26  27 119   4 120  12  12  91 129  94  94  32 118   2\n",
            "   32   2]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "after argmax: [100]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100]\n",
            "token_list is after padding: [[ 34 118   2  26  27 119   4 120  12  12  91 129  94  94  32 118   2  32\n",
            "    2 100]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [101]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101]\n",
            "token_list is after padding: [[118   2  26  27 119   4 120  12  12  91 129  94  94  32 118   2  32   2\n",
            "  100 101]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "after argmax: [102]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102]\n",
            "token_list is after padding: [[  2  26  27 119   4 120  12  12  91 129  94  94  32 118   2  32   2 100\n",
            "  101 102]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [2]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2]\n",
            "token_list is after padding: [[ 26  27 119   4 120  12  12  91 129  94  94  32 118   2  32   2 100 101\n",
            "  102   2]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [31]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31]\n",
            "token_list is after padding: [[ 27 119   4 120  12  12  91 129  94  94  32 118   2  32   2 100 101 102\n",
            "    2  31]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "after argmax: [103]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103]\n",
            "token_list is after padding: [[119   4 120  12  12  91 129  94  94  32 118   2  32   2 100 101 102   2\n",
            "   31 103]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "after argmax: [104]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104]\n",
            "token_list is after padding: [[  4 120  12  12  91 129  94  94  32 118   2  32   2 100 101 102   2  31\n",
            "  103 104]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "after argmax: [105]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105]\n",
            "token_list is after padding: [[120  12  12  91 129  94  94  32 118   2  32   2 100 101 102   2  31 103\n",
            "  104 105]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "after argmax: [106]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106]\n",
            "token_list is after padding: [[ 12  12  91 129  94  94  32 118   2  32   2 100 101 102   2  31 103 104\n",
            "  105 106]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "after argmax: [31]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31]\n",
            "token_list is after padding: [[ 12  91 129  94  94  32 118   2  32   2 100 101 102   2  31 103 104 105\n",
            "  106  31]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "after argmax: [107]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107]\n",
            "token_list is after padding: [[ 91 129  94  94  32 118   2  32   2 100 101 102   2  31 103 104 105 106\n",
            "   31 107]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "after argmax: [108]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108]\n",
            "token_list is after padding: [[129  94  94  32 118   2  32   2 100 101 102   2  31 103 104 105 106  31\n",
            "  107 108]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "after argmax: [32]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32]\n",
            "token_list is after padding: [[ 94  94  32 118   2  32   2 100 101 102   2  31 103 104 105 106  31 107\n",
            "  108  32]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "after argmax: [32]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32]\n",
            "token_list is after padding: [[ 94  32 118   2  32   2 100 101 102   2  31 103 104 105 106  31 107 108\n",
            "   32  32]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "after argmax: [22]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22]\n",
            "token_list is after padding: [[ 32 118   2  32   2 100 101 102   2  31 103 104 105 106  31 107 108  32\n",
            "   32  22]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "after argmax: [22]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22]\n",
            "token_list is after padding: [[118   2  32   2 100 101 102   2  31 103 104 105 106  31 107 108  32  32\n",
            "   22  22]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "after argmax: [33]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33]\n",
            "token_list is after padding: [[  2  32   2 100 101 102   2  31 103 104 105 106  31 107 108  32  32  22\n",
            "   22  33]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "after argmax: [107]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107]\n",
            "token_list is after padding: [[ 32   2 100 101 102   2  31 103 104 105 106  31 107 108  32  32  22  22\n",
            "   33 107]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "after argmax: [80]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80]\n",
            "token_list is after padding: [[  2 100 101 102   2  31 103 104 105 106  31 107 108  32  32  22  22  33\n",
            "  107  80]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "after argmax: [80]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80]\n",
            "token_list is after padding: [[100 101 102   2  31 103 104 105 106  31 107 108  32  32  22  22  33 107\n",
            "   80  80]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "after argmax: [80]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80]\n",
            "token_list is after padding: [[101 102   2  31 103 104 105 106  31 107 108  32  32  22  22  33 107  80\n",
            "   80  80]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "after argmax: [80]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80]\n",
            "token_list is after padding: [[102   2  31 103 104 105 106  31 107 108  32  32  22  22  33 107  80  80\n",
            "   80  80]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "after argmax: [80]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80]\n",
            "token_list is after padding: [[  2  31 103 104 105 106  31 107 108  32  32  22  22  33 107  80  80  80\n",
            "   80  80]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "after argmax: [32]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32]\n",
            "token_list is after padding: [[ 31 103 104 105 106  31 107 108  32  32  22  22  33 107  80  80  80  80\n",
            "   80  32]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "after argmax: [22]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22]\n",
            "token_list is after padding: [[103 104 105 106  31 107 108  32  32  22  22  33 107  80  80  80  80  80\n",
            "   32  22]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "after argmax: [119]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119]\n",
            "token_list is after padding: [[104 105 106  31 107 108  32  32  22  22  33 107  80  80  80  80  80  32\n",
            "   22 119]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "after argmax: [120]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120]\n",
            "token_list is after padding: [[105 106  31 107 108  32  32  22  22  33 107  80  80  80  80  80  32  22\n",
            "  119 120]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "after argmax: [7]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7]\n",
            "token_list is after padding: [[106  31 107 108  32  32  22  22  33 107  80  80  80  80  80  32  22 119\n",
            "  120   7]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "after argmax: [16]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16]\n",
            "token_list is after padding: [[ 31 107 108  32  32  22  22  33 107  80  80  80  80  80  32  22 119 120\n",
            "    7  16]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "after argmax: [1]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1]\n",
            "token_list is after padding: [[107 108  32  32  22  22  33 107  80  80  80  80  80  32  22 119 120   7\n",
            "   16   1]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [8]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8]\n",
            "token_list is after padding: [[108  32  32  22  22  33 107  80  80  80  80  80  32  22 119 120   7  16\n",
            "    1   8]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [9]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9]\n",
            "token_list is after padding: [[ 32  32  22  22  33 107  80  80  80  80  80  32  22 119 120   7  16   1\n",
            "    8   9]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [17]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17]\n",
            "token_list is after padding: [[ 32  22  22  33 107  80  80  80  80  80  32  22 119 120   7  16   1   8\n",
            "    9  17]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [7]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7]\n",
            "token_list is after padding: [[ 22  22  33 107  80  80  80  80  80  32  22 119 120   7  16   1   8   9\n",
            "   17   7]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "after argmax: [42]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42]\n",
            "token_list is after padding: [[ 22  33 107  80  80  80  80  80  32  22 119 120   7  16   1   8   9  17\n",
            "    7  42]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "after argmax: [43]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43]\n",
            "token_list is after padding: [[ 33 107  80  80  80  80  80  32  22 119 120   7  16   1   8   9  17   7\n",
            "   42  43]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "after argmax: [4]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4]\n",
            "token_list is after padding: [[107  80  80  80  80  80  32  22 119 120   7  16   1   8   9  17   7  42\n",
            "   43   4]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "after argmax: [4]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4]\n",
            "token_list is after padding: [[ 80  80  80  80  80  32  22 119 120   7  16   1   8   9  17   7  42  43\n",
            "    4   4]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "after argmax: [86]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86]\n",
            "token_list is after padding: [[ 80  80  80  80  32  22 119 120   7  16   1   8   9  17   7  42  43   4\n",
            "    4  86]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [86]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86]\n",
            "token_list is after padding: [[ 80  80  80  32  22 119 120   7  16   1   8   9  17   7  42  43   4   4\n",
            "   86  86]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "after argmax: [25]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25]\n",
            "token_list is after padding: [[ 80  80  32  22 119 120   7  16   1   8   9  17   7  42  43   4   4  86\n",
            "   86  25]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [23]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23]\n",
            "token_list is after padding: [[ 80  32  22 119 120   7  16   1   8   9  17   7  42  43   4   4  86  86\n",
            "   25  23]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "after argmax: [87]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87]\n",
            "token_list is after padding: [[ 32  22 119 120   7  16   1   8   9  17   7  42  43   4   4  86  86  25\n",
            "   23  87]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "after argmax: [87]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87]\n",
            "token_list is after padding: [[ 22 119 120   7  16   1   8   9  17   7  42  43   4   4  86  86  25  23\n",
            "   87  87]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "after argmax: [99]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99]\n",
            "token_list is after padding: [[119 120   7  16   1   8   9  17   7  42  43   4   4  86  86  25  23  87\n",
            "   87  99]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [31]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31]\n",
            "token_list is after padding: [[120   7  16   1   8   9  17   7  42  43   4   4  86  86  25  23  87  87\n",
            "   99  31]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "after argmax: [107]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107]\n",
            "token_list is after padding: [[  7  16   1   8   9  17   7  42  43   4   4  86  86  25  23  87  87  99\n",
            "   31 107]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "after argmax: [106]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106]\n",
            "token_list is after padding: [[ 16   1   8   9  17   7  42  43   4   4  86  86  25  23  87  87  99  31\n",
            "  107 106]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [31]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31]\n",
            "token_list is after padding: [[  1   8   9  17   7  42  43   4   4  86  86  25  23  87  87  99  31 107\n",
            "  106  31]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [107]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107]\n",
            "token_list is after padding: [[  8   9  17   7  42  43   4   4  86  86  25  23  87  87  99  31 107 106\n",
            "   31 107]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "after argmax: [108]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108]\n",
            "token_list is after padding: [[  9  17   7  42  43   4   4  86  86  25  23  87  87  99  31 107 106  31\n",
            "  107 108]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [32]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32]\n",
            "token_list is after padding: [[ 17   7  42  43   4   4  86  86  25  23  87  87  99  31 107 106  31 107\n",
            "  108  32]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [32]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32]\n",
            "token_list is after padding: [[  7  42  43   4   4  86  86  25  23  87  87  99  31 107 106  31 107 108\n",
            "   32  32]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [22]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22]\n",
            "token_list is after padding: [[ 42  43   4   4  86  86  25  23  87  87  99  31 107 106  31 107 108  32\n",
            "   32  22]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "after argmax: [22]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22]\n",
            "token_list is after padding: [[ 43   4   4  86  86  25  23  87  87  99  31 107 106  31 107 108  32  32\n",
            "   22  22]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [79]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79]\n",
            "token_list is after padding: [[  4   4  86  86  25  23  87  87  99  31 107 106  31 107 108  32  32  22\n",
            "   22  79]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [23]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23]\n",
            "token_list is after padding: [[  4  86  86  25  23  87  87  99  31 107 106  31 107 108  32  32  22  22\n",
            "   79  23]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [80]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80]\n",
            "token_list is after padding: [[ 86  86  25  23  87  87  99  31 107 106  31 107 108  32  32  22  22  79\n",
            "   23  80]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "after argmax: [80]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80]\n",
            "token_list is after padding: [[ 86  25  23  87  87  99  31 107 106  31 107 108  32  32  22  22  79  23\n",
            "   80  80]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "after argmax: [80]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80]\n",
            "token_list is after padding: [[ 25  23  87  87  99  31 107 106  31 107 108  32  32  22  22  79  23  80\n",
            "   80  80]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "after argmax: [99]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99]\n",
            "token_list is after padding: [[ 23  87  87  99  31 107 106  31 107 108  32  32  22  22  79  23  80  80\n",
            "   80  99]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [29]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29]\n",
            "token_list is after padding: [[ 87  87  99  31 107 106  31 107 108  32  32  22  22  79  23  80  80  80\n",
            "   99  29]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [12]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29, 12]\n",
            "token_list is after padding: [[ 87  99  31 107 106  31 107 108  32  32  22  22  79  23  80  80  80  99\n",
            "   29  12]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "after argmax: [12]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29, 12, 12]\n",
            "token_list is after padding: [[ 99  31 107 106  31 107 108  32  32  22  22  79  23  80  80  80  99  29\n",
            "   12  12]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "after argmax: [91]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29, 12, 12, 91]\n",
            "token_list is after padding: [[ 31 107 106  31 107 108  32  32  22  22  79  23  80  80  80  99  29  12\n",
            "   12  91]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "after argmax: [92]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29, 12, 12, 91, 92]\n",
            "token_list is after padding: [[107 106  31 107 108  32  32  22  22  79  23  80  80  80  99  29  12  12\n",
            "   91  92]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "after argmax: [93]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29, 12, 12, 91, 92, 93]\n",
            "token_list is after padding: [[106  31 107 108  32  32  22  22  79  23  80  80  80  99  29  12  12  91\n",
            "   92  93]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "after argmax: [94]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29, 12, 12, 91, 92, 93, 94]\n",
            "token_list is after padding: [[ 31 107 108  32  32  22  22  79  23  80  80  80  99  29  12  12  91  92\n",
            "   93  94]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "after argmax: [25]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29, 12, 12, 91, 92, 93, 94, 25]\n",
            "token_list is after padding: [[107 108  32  32  22  22  79  23  80  80  80  99  29  12  12  91  92  93\n",
            "   94  25]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "after argmax: [109]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29, 12, 12, 91, 92, 93, 94, 25, 109]\n",
            "token_list is after padding: [[108  32  32  22  22  79  23  80  80  80  99  29  12  12  91  92  93  94\n",
            "   25 109]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [34]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29, 12, 12, 91, 92, 93, 94, 25, 109, 34]\n",
            "token_list is after padding: [[ 32  32  22  22  79  23  80  80  80  99  29  12  12  91  92  93  94  25\n",
            "  109  34]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "after argmax: [110]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29, 12, 12, 91, 92, 93, 94, 25, 109, 34, 110]\n",
            "token_list is after padding: [[ 32  22  22  79  23  80  80  80  99  29  12  12  91  92  93  94  25 109\n",
            "   34 110]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "after argmax: [3]\n",
            "token_list is: [5, 21, 3, 114, 32, 115, 117, 13, 28, 34, 118, 2, 26, 27, 119, 4, 120, 12, 12, 91, 129, 94, 94, 32, 118, 2, 32, 2, 100, 101, 102, 2, 31, 103, 104, 105, 106, 31, 107, 108, 32, 32, 22, 22, 33, 107, 80, 80, 80, 80, 80, 32, 22, 119, 120, 7, 16, 1, 8, 9, 17, 7, 42, 43, 4, 4, 86, 86, 25, 23, 87, 87, 99, 31, 107, 106, 31, 107, 108, 32, 32, 22, 22, 79, 23, 80, 80, 80, 99, 29, 12, 12, 91, 92, 93, 94, 25, 109, 34, 110, 3]\n",
            "token_list is after padding: [[ 22  22  79  23  80  80  80  99  29  12  12  91  92  93  94  25 109  34\n",
            "  110   3]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "after argmax: [111]\n",
            "agentic ai use cases are agent software system designed autonomously achieve specific goals perceiving environment making decisions taking actions complete tasks tasks without goal intervention intervention system perceiving environment system environment whether thats physical environment like robot vacuum digital one like customer support system system tools tools execute customer problems problems problems problems problems system tools taking complete learning adaptability agents improve performance time learning experiences consequences actions actions coordinate coordinate perform complex operations operations performing like customer one like customer support system system tools tools solve complex problems problems problems performing necessary tasks tasks without constant human intervention perform based goals understanding agent formulates\n"
          ]
        }
      ]
    }
  ]
}